{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b09633",
   "metadata": {},
   "source": [
    "#### Demostrating text pre-prcessing pipelines using POS tagging, NER, and polysemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b8162a-32cc-4f01-ab95-5851dff86d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging:\n",
      "The: DT\n",
      "lead: NN\n",
      "engineer: NN\n",
      "for: IN\n",
      "the: DT\n",
      "new: JJ\n",
      "bridge: NN\n",
      "project: NN\n",
      "made: VBD\n",
      "a: DT\n",
      "breakthrough: NN\n",
      "in: IN\n",
      "New: NNP\n",
      "York: NNP\n",
      ".: .\n",
      "The: DT\n",
      "team: NN\n",
      "is: VBZ\n",
      "now: RB\n",
      "looking: VBG\n",
      "at: IN\n",
      "the: DT\n",
      "potential: JJ\n",
      "impacts: NNS\n",
      "of: IN\n",
      "their: PRP$\n",
      "findings: NNS\n",
      "on: IN\n",
      "the: DT\n",
      "new: JJ\n",
      "soil: NN\n",
      ".: .\n",
      "Meanwhile: RB\n",
      ",: ,\n",
      "Virat: NNP\n",
      "Kohli: NNP\n",
      "hit: VBD\n",
      "his: PRP$\n",
      "double: JJ\n",
      "ton: NN\n",
      "in: IN\n",
      "sports: NNS\n",
      "news: NN\n",
      "last: JJ\n",
      "night: NN\n",
      ".: .\n",
      "The: DT\n",
      "lead: JJ\n",
      "engineer: NN\n",
      "of: IN\n",
      "the: DT\n",
      "project: NN\n",
      "team: NN\n",
      "is: VBZ\n",
      "highly: RB\n",
      "respected: VBN\n",
      ".: .\n",
      "\n",
      "Named Entity Recognition:\n",
      "New York: GPE\n",
      "Virat Kohli: PERSON\n",
      "\n",
      "Polysemy Detection:\n",
      "'lead' has multiple meanings.\n",
      "'engineer' has multiple meanings.\n",
      "'new' has multiple meanings.\n",
      "'bridge' has multiple meanings.\n",
      "'project' has multiple meanings.\n",
      "'made' has multiple meanings.\n",
      "'a' has multiple meanings.\n",
      "'breakthrough' has multiple meanings.\n",
      "'in' has multiple meanings.\n",
      "'New' has multiple meanings.\n",
      "'team' has multiple meanings.\n",
      "'is' has multiple meanings.\n",
      "'now' has multiple meanings.\n",
      "'looking' has multiple meanings.\n",
      "'at' has multiple meanings.\n",
      "'potential' has multiple meanings.\n",
      "'impacts' has multiple meanings.\n",
      "'findings' has multiple meanings.\n",
      "'on' has multiple meanings.\n",
      "'new' has multiple meanings.\n",
      "'soil' has multiple meanings.\n",
      "'Meanwhile' has multiple meanings.\n",
      "'hit' has multiple meanings.\n",
      "'double' has multiple meanings.\n",
      "'ton' has multiple meanings.\n",
      "'in' has multiple meanings.\n",
      "'sports' has multiple meanings.\n",
      "'news' has multiple meanings.\n",
      "'last' has multiple meanings.\n",
      "'night' has multiple meanings.\n",
      "'lead' has multiple meanings.\n",
      "'engineer' has multiple meanings.\n",
      "'project' has multiple meanings.\n",
      "'team' has multiple meanings.\n",
      "'is' has multiple meanings.\n",
      "'highly' has multiple meanings.\n",
      "'respected' has multiple meanings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Shailendra\n",
      "[nltk_data]     Kadre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shailendra Kadre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Shailendra Kadre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Shailendra\n",
      "[nltk_data]     Kadre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Shailendra\n",
      "[nltk_data]     Kadre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, ne_chunk\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function for POS Tagging\n",
    "def pos_tagging(tokens):\n",
    "    return pos_tag(tokens)\n",
    "\n",
    "# Function for Named Entity Recognition\n",
    "def named_entity_recognition(pos_tags):\n",
    "    return ne_chunk(pos_tags)\n",
    "\n",
    "# Function for Polysemy Detection\n",
    "def find_polysemy(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return len(synsets) > 1\n",
    "\n",
    "# Function to run the complete text processing pipeline\n",
    "def text_processing_pipeline(text):\n",
    "    # Step 1: Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 2: POS Tagging\n",
    "    pos_tags = pos_tagging(tokens)\n",
    "    print(\"POS Tagging:\")\n",
    "    for word, tag in pos_tags:\n",
    "        print(f\"{word}: {tag}\")\n",
    "    \n",
    "    # Step 3: Named Entity Recognition\n",
    "    ner_tree = named_entity_recognition(pos_tags)\n",
    "    print(\"\\nNamed Entity Recognition:\")\n",
    "    for subtree in ner_tree:\n",
    "        if hasattr(subtree, 'label'):\n",
    "            print(f\"{' '.join(c[0] for c in subtree)}: {subtree.label()}\")\n",
    "    \n",
    "    # Step 4: Polysemy Detection\n",
    "    print(\"\\nPolysemy Detection:\")\n",
    "    for token in tokens:\n",
    "        if find_polysemy(token):\n",
    "            print(f\"'{token}' has multiple meanings.\")\n",
    "\n",
    "# Example article text\n",
    "article_text = \"\"\"\n",
    "The lead engineer for the new bridge project made a breakthrough in New York. \n",
    "The team is now looking at the potential impacts of their findings on the new soil. \n",
    "Meanwhile, Virat Kohli hit his double ton in sports news last night. \n",
    "The lead engineer of the project team is highly respected.\n",
    "\"\"\"\n",
    "# Run the text processing pipeline\n",
    "text_processing_pipeline(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4e527-168f-41db-9323-5e1d2e4c7bbb",
   "metadata": {},
   "source": [
    "Code Snippet 6.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
