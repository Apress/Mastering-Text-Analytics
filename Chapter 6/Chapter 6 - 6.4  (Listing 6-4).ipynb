{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b09633",
   "metadata": {},
   "source": [
    "#### Tutorial on Synonyms, Antonyms, Homophones, Homographs, Polysemy, and Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4024cb7-0bfc-4203-b745-9687c3f61013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the nltk library for text processing\n",
    "import nltk\n",
    "\n",
    "# Imports WordNet to access synonyms, antonyms, and word meanings.\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Imports the function to tokenize text into words.\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35388478-66b8-4672-bb40-95d80bbe1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the WordNet lexical database.\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Downloads the Open multilingual WordNet package. \n",
    "# It is needed for some language-related tasks.\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Downloads the Punkt tokenizer models for sentence and word tokenization.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea49cf7d-8738-4984-ae0b-a724ab8ed1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the sample text.\n",
    "article_text = \"\"\"\n",
    "The lead engineer in the new bridge project has made a breakthrough. \n",
    "The team is now looking at the potential impacts of their findings on the new soil. \n",
    "Meanwhile, a local cricket player hit his double ton in sports news last night. \n",
    "The lead engineer of the project team is highly respected.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a035d239-1ab7-4b84-ba6a-104e9310ca38",
   "metadata": {},
   "source": [
    "#### Tokenize the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdccf550-e7a9-4edd-bc9a-54c760c45617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizes the article text into individual words or tokens.\n",
    "tokens = word_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598ad63-8eeb-49d0-8ed0-1cff071d2be7",
   "metadata": {},
   "source": [
    "#### 1. Synonyms Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3296c3c1-ac7a-47b8-93f2-c8ff3dfcc9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms Detection:\n",
      "No synonyms found for 'The'\n",
      "Synonyms for 'lead': wind, steer, lead-in, Pb, lede, jumper_lead, extend, trail, guide, moderate, head, booster_cable, precede, tip, result, jumper_cable, confidential_information, pass, principal, atomic_number_82, run, track, lead_story, take, pencil_lead, leading, tether, contribute, star, hint, direct, conduct, leave, conduce, lead, top, go, spark_advance, leash, chair\n",
      "Synonyms for 'engineer': organise, mastermind, engineer, technologist, direct, orchestrate, applied_scientist, railroad_engineer, locomotive_engineer, engine_driver, organize\n",
      "Synonyms for 'in': inch, IN, Indiana, In, inward, inwards, in, indium, atomic_number_49, Hoosier_State\n",
      "No synonyms found for 'the'\n"
     ]
    }
   ],
   "source": [
    "# Prints the header for synonym detection.\n",
    "print(\"Synonyms Detection:\")\n",
    "\n",
    "# Iterates over the first 5 tokens.\n",
    "for token in tokens[:5]:\n",
    "    # Retrieves WordNet synsets for the token.\n",
    "    synsets = wn.synsets(token)\n",
    "    \n",
    "    # Initializes a set to collect synonyms.\n",
    "    synonyms = set()\n",
    "    \n",
    "    # Iterates over each synset to gather synonyms.\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    \n",
    "    # Prints the synonyms if found, otherwise, it indicates none were found.\n",
    "    if synonyms:\n",
    "        print(f\"Synonyms for '{token}': {', '.join(synonyms)}\")\n",
    "    else:\n",
    "        print(f\"No synonyms found for '{token}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38edb7f-8793-4894-9aa9-243b4e917fa6",
   "metadata": {},
   "source": [
    "#### 2. Antonyms Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f89cec2-58f3-42e0-a9aa-b07a4a839116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Antonyms Detection:\n",
      "Antonyms for 'lead': follow, deficit\n",
      "Antonyms for 'new': worn, old\n",
      "Antonyms for 'has': refuse, lack, abstain\n",
      "Antonyms for 'made': unmake, unmade, break\n",
      "Antonyms for 'is': differ\n",
      "Antonyms for 'looking': back\n",
      "Antonyms for 'potential': actual\n",
      "Antonyms for 'findings': lose\n",
      "Antonyms for 'on': off\n",
      "Antonyms for 'new': worn, old\n",
      "Antonyms for 'soil': clean\n",
      "Antonyms for 'local': express, national, general\n",
      "Antonyms for 'hit': miss\n",
      "Antonyms for 'double': multivalent, single, univalent\n",
      "Antonyms for 'last': first\n",
      "Antonyms for 'night': day\n",
      "Antonyms for 'lead': follow, deficit\n",
      "Antonyms for 'is': differ\n",
      "Antonyms for 'respected': disesteem, disrespect\n"
     ]
    }
   ],
   "source": [
    "# Prints the header for antonym detection.\n",
    "print(\"\\nAntonyms Detection:\")\n",
    "\n",
    "# Iterates over each token.\n",
    "for token in tokens:\n",
    "    # Retrieves WordNet synsets for the token.\n",
    "    synsets = wn.synsets(token)\n",
    "    \n",
    "    # Initializes a set to collect antonyms.\n",
    "    antonyms = set()\n",
    "    \n",
    "    # Iterates over each synset to gather antonyms.\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            # Checks for antonyms and adds them to the set.\n",
    "            if lemma.antonyms():\n",
    "                antonyms.update(ant.name() for ant in lemma.antonyms())\n",
    "    \n",
    "    # Prints the antonyms if found.\n",
    "    if antonyms:\n",
    "        print(f\"Antonyms for '{token}': {', '.join(antonyms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184d2b6-bb3f-4fe9-a764-73fe5e6ddb04",
   "metadata": {},
   "source": [
    "#### 3. Homophones Detection (alternate approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e47b567-fa06-4d11-be7c-97dec8e12d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homophones Detection:\n",
      "Homophones for 'lead': led\n",
      "Homophones for 'lead': led\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHomophones Detection:\")\n",
    "# Homophones are generally detected using phonetic algorithms or external libraries like `fuzzy` or `PyDictionary`. \n",
    "# Here we might use a simple custom method based on pronunciation or external data sources.\n",
    "\n",
    "# Defines a function to check if two words are homophones based on a simplified rule.\n",
    "def is_homophone(word1, word2):\n",
    "    return word1.lower() == word2.lower() and word1 != word2\n",
    "\n",
    "# Example list of homophone pairs.\n",
    "homophones_list = [('lead', 'led'), ('bare', 'bear'), ('pair', 'pear')]\n",
    "\n",
    "# Iterates over each token.\n",
    "for token in tokens:\n",
    "    # Finds homophones for the current token based on the example list.\n",
    "    homophones = [pair[1] for pair in homophones_list if pair[0] == token.lower()]\n",
    "    \n",
    "    # Prints homophones if found.\n",
    "    if homophones:\n",
    "        print(f\"Homophones for '{token}': {', '.join(homophones)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27366c6c-25f9-4c32-8879-056855131dea",
   "metadata": {},
   "source": [
    "#### 4. Homographs Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d07b1df-502b-420f-9bb6-8332ef50f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homographs Detection:\n",
      "'lead' is a homograph with POS tags: v, n\n",
      "'engineer' is a homograph with POS tags: v, n\n",
      "'in' is a homograph with POS tags: r, s, n\n",
      "'new' is a homograph with POS tags: s, a, r\n",
      "'bridge' is a homograph with POS tags: v, n\n",
      "'project' is a homograph with POS tags: v, n\n",
      "'has' is a homograph with POS tags: v, n\n",
      "'made' is a homograph with POS tags: v, s, a\n",
      "'team' is a homograph with POS tags: v, n\n",
      "'now' is a homograph with POS tags: r, n\n",
      "'looking' is a homograph with POS tags: v, s, n\n",
      "'potential' is a homograph with POS tags: s, a, n\n",
      "'impacts' is a homograph with POS tags: v, n\n",
      "'findings' is a homograph with POS tags: v, n\n",
      "'on' is a homograph with POS tags: a, r\n",
      "'new' is a homograph with POS tags: s, a, r\n",
      "'soil' is a homograph with POS tags: v, n\n",
      "'Meanwhile' is a homograph with POS tags: r, n\n",
      "'local' is a homograph with POS tags: a, n\n",
      "'cricket' is a homograph with POS tags: v, n\n",
      "'hit' is a homograph with POS tags: v, n\n",
      "'double' is a homograph with POS tags: a, r, n, s, v\n",
      "'in' is a homograph with POS tags: r, s, n\n",
      "'sports' is a homograph with POS tags: v, n\n",
      "'last' is a homograph with POS tags: a, r, n, s, v\n",
      "'lead' is a homograph with POS tags: v, n\n",
      "'engineer' is a homograph with POS tags: v, n\n",
      "'project' is a homograph with POS tags: v, n\n",
      "'team' is a homograph with POS tags: v, n\n",
      "'respected' is a homograph with POS tags: v, s\n"
     ]
    }
   ],
   "source": [
    "# Prints the header for homograph detection.\n",
    "print(\"\\nHomographs Detection:\")\n",
    "\n",
    "# Iterates over each token.\n",
    "for token in tokens:\n",
    "    # Retrieves WordNet synsets for the token.\n",
    "    synsets = wn.synsets(token)\n",
    "    \n",
    "    # Initializes a set to collect part-of-speech tags.\n",
    "    pos_tags = set()\n",
    "    \n",
    "    # Adds POS tags for each synset to the set.\n",
    "    for synset in synsets:\n",
    "        pos_tags.add(synset.pos())\n",
    "    \n",
    "    # Prints if the token has multiple POS tags, indicating it is a homograph.\n",
    "    if len(pos_tags) > 1:\n",
    "        print(f\"'{token}' is a homograph with POS tags: {', '.join(pos_tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577e5d1-d126-447f-a51f-2c43623a2499",
   "metadata": {},
   "source": [
    "#### 5. Polysemy Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a682870-46f8-4ae9-a2e8-d07b7da312e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polysemy Detection:\n",
      "'lead' has multiple meanings.\n",
      "'engineer' has multiple meanings.\n",
      "'in' has multiple meanings.\n",
      "'new' has multiple meanings.\n",
      "'bridge' has multiple meanings.\n",
      "'project' has multiple meanings.\n",
      "'has' has multiple meanings.\n",
      "'made' has multiple meanings.\n",
      "'a' has multiple meanings.\n",
      "'breakthrough' has multiple meanings.\n",
      "'team' has multiple meanings.\n",
      "'is' has multiple meanings.\n",
      "'now' has multiple meanings.\n",
      "'looking' has multiple meanings.\n",
      "'at' has multiple meanings.\n",
      "'potential' has multiple meanings.\n",
      "'impacts' has multiple meanings.\n",
      "'findings' has multiple meanings.\n",
      "'on' has multiple meanings.\n",
      "'new' has multiple meanings.\n",
      "'soil' has multiple meanings.\n",
      "'Meanwhile' has multiple meanings.\n",
      "'a' has multiple meanings.\n",
      "'local' has multiple meanings.\n",
      "'cricket' has multiple meanings.\n",
      "'player' has multiple meanings.\n",
      "'hit' has multiple meanings.\n",
      "'double' has multiple meanings.\n",
      "'ton' has multiple meanings.\n",
      "'in' has multiple meanings.\n",
      "'sports' has multiple meanings.\n",
      "'news' has multiple meanings.\n",
      "'last' has multiple meanings.\n",
      "'night' has multiple meanings.\n",
      "'lead' has multiple meanings.\n",
      "'engineer' has multiple meanings.\n",
      "'project' has multiple meanings.\n",
      "'team' has multiple meanings.\n",
      "'is' has multiple meanings.\n",
      "'highly' has multiple meanings.\n",
      "'respected' has multiple meanings.\n"
     ]
    }
   ],
   "source": [
    "# Prints the header for polysemy detection.\n",
    "print(\"\\nPolysemy Detection:\")\n",
    "\n",
    "# Iterates over each token.\n",
    "for token in tokens:\n",
    "    # Retrieves WordNet synsets for the token.\n",
    "    synsets = wn.synsets(token)\n",
    "    \n",
    "    # Prints if the token has more than one synset, indicating multiple meanings.\n",
    "    if len(synsets) > 1:\n",
    "        print(f\"'{token}' has multiple meanings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b51f66f-13ea-46fe-aa90-c2725be36bc3",
   "metadata": {},
   "source": [
    "#### 6. Hyponyms of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "934b91b0-91bd-42db-9a93-0cd79c690380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to find hyponyms for a given word.\n",
    "def find_hyponyms(word):\n",
    "    # Initializes a set to collect hyponyms.\n",
    "    hyponyms = set()\n",
    "    \n",
    "    # Retrieves WordNet synsets for the given word.\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    # Iterates over each synset to find hyponyms.\n",
    "    for synset in synsets:\n",
    "        for hyponym in synset.hyponyms():\n",
    "            for lemma in hyponym.lemmas():\n",
    "                # Adds hyponyms to the set.\n",
    "                hyponyms.add(lemma.name())\n",
    "    \n",
    "    # Returns the set of hyponyms.\n",
    "    return hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684f6fc-a797-4380-be31-8388e426e6c6",
   "metadata": {},
   "source": [
    "#### 7. Categorize the article based on hyponyms of given categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcfa2e31-e908-45bb-bd2d-4d1248dcdee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'scientist': No matching terms found\n",
      "Category 'research': No matching terms found\n",
      "Category 'sports': No matching terms found\n",
      "Category 'team': No matching terms found\n",
      "Category 'player': lead, lead\n"
     ]
    }
   ],
   "source": [
    "# Defines a function to categorize terms in the text based on hyponyms of given categories.\n",
    "def categorize_article(text, category_terms):\n",
    "    # Tokenizes and lowercases the text.\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Initializes a dictionary to store categorized terms.\n",
    "    categorized_terms = {term: [] for term in category_terms}\n",
    "    \n",
    "    # Iterates over each token.\n",
    "    for token in tokens:\n",
    "        # Checks each category term for matching hyponyms.\n",
    "        for term in category_terms:\n",
    "            hyponyms = find_hyponyms(term)\n",
    "            if token in hyponyms:\n",
    "                # Appends the token to the corresponding category.\n",
    "                categorized_terms[term].append(token)\n",
    "    \n",
    "    # Returns the dictionary of categorized terms.\n",
    "    return categorized_terms\n",
    "\n",
    "# Categorizes terms in the article text based on specified general categories.\n",
    "categories = categorize_article(article_text, [\"scientist\", \"research\", \"sports\", \"team\", \"player\"])\n",
    "\n",
    "# Print out the categorized terms or a message if none are found.\n",
    "for category, items in categories.items():\n",
    "    if items:\n",
    "        print(f\"Category '{category}': {', '.join(items)}\")\n",
    "    else:\n",
    "        print(f\"Category '{category}': No matching terms found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4e527-168f-41db-9323-5e1d2e4c7bbb",
   "metadata": {},
   "source": [
    "Code Snippet 6.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
