{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e641118f-3248-4481-ac08-0452d94debb1",
   "metadata": {},
   "source": [
    "### Business Document Processing: Summarization, Keyword Extraction, and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df262b-22b0-4548-a2f0-49197b449863",
   "metadata": {},
   "source": [
    "- Loads and processes diverse business documents (PDF, HTML, CSV) for analysis.\n",
    "- Summarizes document content for quick business insights using GPT-3.5.\n",
    "- Extracts key business-relevant keywords to aid decision-making.\n",
    "- Performs sentiment analysis on customer feedback to gauge satisfaction.\n",
    "- Provides efficient business document analysis through automated text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b70cb8c-950a-4313-abb7-4d3f048ae5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the open ai API key from your text file\n",
    "f = open('C:\\\\Users\\\\Shailendra Kadre\\\\Desktop\\\\OPEN_AI_KEY.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2539ee68-9ef6-4357-a050-2676e34f215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13bea136-62f7-43bb-ad20-bf6f11dd46dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Shailendra Kadre\\AppData\\Local\\Temp\\ipykernel_7416\\3285144398.py:27: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  pdf_loader = PyPDFLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_pdf.pdf\")  # Load a PDF file\n",
      "C:\\Users\\Shailendra Kadre\\AppData\\Local\\Temp\\ipykernel_7416\\3285144398.py:30: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  html_loader = UnstructuredHTMLLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_html.html\")  # Load an HTML file\n",
      "C:\\Users\\Shailendra Kadre\\AppData\\Local\\Temp\\ipykernel_7416\\3285144398.py:33: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  csv_loader = CSVLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_csv.csv\")  # Load a CSV file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PDF Summary ---\n",
      " {'text': 'The document discusses various topics related to business, such as market analysis and customer behavior. It also includes a chart with rows and columns displaying numerical data.'}\n",
      "\n",
      "--- HTML Summary ---\n",
      " {'text': 'The document discusses the comparison between medicine and government with wisdom being the ultimate goal. It questions why people do not prefer to talk about important matters when they have the opportunity to do so. It also raises the issue of whether prolonged suffering makes one more miserable, or if prolonged pleasure is preferred.'}\n",
      "\n",
      "--- CSV Summary ---\n",
      " {'text': 'The document provides information related to accounting and finance industry. It may cover topics such as financial analysis, budgeting, auditing, taxation, and financial reporting. The document could provide insights into best practices, industry trends, regulations, and challenges within the accounting and finance sector.'}\n",
      "\n",
      "--- PDF Keywords ---\n",
      " {'text': '1. Lorem\\n2. Maecenas\\n3. Condimentum\\n4. Nullam\\n5. Fringilla'}\n",
      "\n",
      "--- HTML Keywords ---\n",
      " {'text': '1. lorem\\n2. ipsum\\n3. consectetur\\n4. adipiscing\\n5. elit'}\n",
      "\n",
      "--- CSV Keywords ---\n",
      " {'text': '1. Accounting\\n2. Finance\\n3. Industry\\n4. Financial\\n5. Management'}\n",
      "\n",
      "--- CSV Sentiment Analysis ---\n",
      " \"Absolutely fantastic service from the accounting team. They were able to solve all of my financial issues and provide me with great advice. Highly recommend their services.\"\n",
      "\n",
      "Sentiment: Positive.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os  # Provides functions for interacting with the operating system\n",
    "\n",
    "# Import document loaders for handling different file types\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredHTMLLoader, CSVLoader\n",
    "\n",
    "# PyPDFLoader: Used to load PDF files\n",
    "# UnstructuredHTMLLoader: Used to load and process HTML files\n",
    "# CSVLoader: Used to load CSV files\n",
    "\n",
    "# Import a text splitter to break documents into manageable chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# CharacterTextSplitter: Splits text into smaller segments while maintaining context\n",
    "\n",
    "# Import ChatOpenAI for interacting with OpenAI's language models\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Import prompt-related utilities to format queries for the AI model\n",
    "from langchain.prompts import PromptTemplate  # Creates structured prompts for AI input\n",
    "\n",
    "# Import LLMChain to execute AI workflows using prompts\n",
    "from langchain.chains import LLMChain  \n",
    "\n",
    "# Load and parse documents from different file formats\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_pdf.pdf\")  # Load a PDF file\n",
    "pdf_docs = pdf_loader.load()  # Read content from the PDF file\n",
    "\n",
    "html_loader = UnstructuredHTMLLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_html.html\")  # Load an HTML file\n",
    "html_docs = html_loader.load()  # Read content from the HTML file\n",
    "\n",
    "csv_loader = CSVLoader(\"C:\\AA SK 53\\After IBA Aug 21 2024\\Christ University\\MDPs\\DL & GenAI\\sample_csv.csv\")  # Load a CSV file\n",
    "csv_docs = csv_loader.load()  # Read content from the CSV file\n",
    "\n",
    "# Text Splitting for easier processing and model handling\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)  \n",
    "# Splits text into chunks of 500 characters with 50-character overlap to preserve context\n",
    "\n",
    "pdf_chunks = splitter.split_documents(pdf_docs)  # Split PDF content into smaller chunks\n",
    "html_chunks = splitter.split_documents(html_docs)  # Split HTML content into smaller chunks\n",
    "csv_chunks = splitter.split_documents(csv_docs)  # Split CSV content into smaller chunks\n",
    "\n",
    "# Initialize the OpenAI chat model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=api_key)  \n",
    "# - Uses GPT-3.5-turbo model with the given API key\n",
    "\n",
    "# Define a prompt template for summarization\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],  \n",
    "    template=\"Summarize the following business document:\\n{text}\"  \n",
    "    # Creates a template where {text} will be replaced with actual document content\n",
    ")\n",
    "\n",
    "# Create an LLM chain for summarization\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)  \n",
    "# Uses the ChatOpenAI model with the defined summarization prompt\n",
    "\n",
    "# Generate summaries for each document type\n",
    "pdf_summary = summary_chain.invoke({\"text\": pdf_chunks[0].page_content})  \n",
    "html_summary = summary_chain.invoke({\"text\": html_chunks[0].page_content})  \n",
    "csv_summary = summary_chain.invoke({\"text\": csv_chunks[0].page_content})  \n",
    "\n",
    "# Print the generated summaries\n",
    "print(\"\\n--- PDF Summary ---\\n\", pdf_summary)  \n",
    "print(\"\\n--- HTML Summary ---\\n\", html_summary)  \n",
    "print(\"\\n--- CSV Summary ---\\n\", csv_summary)  \n",
    "\n",
    "# Define a prompt template for keyword extraction\n",
    "keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],  \n",
    "    template=\"Extract the top 5 keywords from the following document:\\n{text}\"  \n",
    "    # Creates a structured request for extracting keywords\n",
    ")\n",
    "\n",
    "# Create an LLM chain for keyword extraction\n",
    "keyword_chain = LLMChain(llm=llm, prompt=keyword_prompt)  \n",
    "\n",
    "# Extract keywords from each document type\n",
    "pdf_keywords = keyword_chain.invoke({\"text\": pdf_chunks[0].page_content})  \n",
    "html_keywords = keyword_chain.invoke({\"text\": html_chunks[0].page_content})  \n",
    "csv_keywords = keyword_chain.invoke({\"text\": csv_chunks[0].page_content})  \n",
    "\n",
    "# Print extracted keywords\n",
    "print(\"\\n--- PDF Keywords ---\\n\", pdf_keywords)  \n",
    "print(\"\\n--- HTML Keywords ---\\n\", html_keywords)  \n",
    "print(\"\\n--- CSV Keywords ---\\n\", csv_keywords)  \n",
    "\n",
    "# Define a prompt template for sentiment analysis\n",
    "sentiment_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],  \n",
    "    template=\"Analyze the sentiment of the following customer feedback and rate as Positive, Neutral, or Negative:\\n{text}\"  \n",
    "    # Asks AI to classify sentiment as Positive, Neutral, or Negative\n",
    ")\n",
    "\n",
    "# Create an LLM chain for sentiment analysis\n",
    "sentiment_chain = LLMChain(llm=llm, prompt=sentiment_prompt)  \n",
    "\n",
    "# Perform sentiment analysis on the CSV document\n",
    "csv_sentiment = sentiment_chain.invoke({\"text\": csv_chunks[0].page_content})  \n",
    "\n",
    "# Print the sentiment analysis result\n",
    "print(\"\\n--- CSV Sentiment Analysis ---\\n\", csv_sentiment['text']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358afd93-3c7b-4082-a78e-7fab38a0fef0",
   "metadata": {},
   "source": [
    "- The LLMChain in the code acts as a structured pipeline that takes an input, processes it using a language model, and returns an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb2267-571f-483b-a66c-159a8b5a9605",
   "metadata": {},
   "source": [
    "- Since pdf_chunks[0].page_content only processes the first chunk, it summarizes only that portion, not the entire document. \n",
    "- To summarize the full document, you need to iterate through all chunks and combine their summaries.\n",
    "- A final summary can then be generated by summarizing the combined outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bee69a-05dc-4714-bd60-a30fd96b221d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
