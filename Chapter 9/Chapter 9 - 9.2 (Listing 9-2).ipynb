{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085a6b57-4cec-41cf-8f42-521a35f6879e",
   "metadata": {},
   "source": [
    "### Document Transformers – Splitting Text for NLP Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d879854-868c-433a-b669-2f4a1ab1a935",
   "metadata": {},
   "source": [
    "- Overview: Demonstrates how to split text into sentences, words, and characters using LangChain.\n",
    "- File Handling: Loads text from sample_text.txt using LangChain’s TextLoader.\n",
    "- Sentence Splitting: Uses CharacterTextSplitter with a period separator.\n",
    "- Token Splitting: Splits words based on whitespace.\n",
    "- Character Splitting: Converts text into individual characters for fine-grained analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240b9f46-3195-4bf1-a9db-ec710364c68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SPLIT BY PERIOD (SENTENCES) ---\n",
      "['LangChain is a framework for developing applications powered by large language models.  \\nIt helps with data retrieval, memory, and document processing.  \\nAI agents use LangChain to handle conversations and reasoning.']\n",
      "\n",
      "--- SPLIT BY TOKEN (WORDS) ---\n",
      "['LangChain', 'is', 'a', 'framework', 'for', 'developing', 'applications', 'powered', 'by', 'large', 'language', 'models.', 'It', 'helps', 'with', 'data', 'retrieval,', 'memory,', 'and', 'document', 'processing.', 'AI', 'agents', 'use', 'LangChain', 'to', 'handle', 'conversations', 'and', 'reasoning.']\n",
      "\n",
      "--- SPLIT BY CHARACTER ---\n",
      "['L', 'a', 'n', 'g', 'C', 'h', 'a', 'i', 'n', ' ', 'i', 's', ' ', 'a', ' ', 'f', 'r', 'a', 'm', 'e', 'w', 'o', 'r', 'k', ' ', 'f', 'o', 'r', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'i', 'n', 'g', ' ', 'a', 'p', 'p', 'l', 'i', 'c', 'a', 't', 'i', 'o', 'n', 's', ' ', 'p', 'o', 'w', 'e', 'r', 'e', 'd', ' ', 'b', 'y', ' ', 'l', 'a', 'r', 'g', 'e', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', ' ', 'm', 'o', 'd', 'e', 'l', 's', '.', ' ', ' ', '\\n', 'I', 't', ' ', 'h', 'e', 'l', 'p', 's', ' ', 'w', 'i', 't', 'h', ' ', 'd', 'a', 't', 'a', ' ', 'r', 'e', 't', 'r', 'i', 'e', 'v', 'a', 'l', ',', ' ', 'm', 'e', 'm', 'o', 'r', 'y', ',', ' ', 'a', 'n', 'd', ' ', 'd', 'o', 'c', 'u', 'm', 'e', 'n', 't', ' ', 'p', 'r', 'o', 'c', 'e', 's', 's', 'i', 'n', 'g', '.', ' ', ' ', '\\n', 'A', 'I', ' ', 'a', 'g', 'e', 'n', 't', 's', ' ', 'u', 's', 'e', ' ', 'L', 'a', 'n', 'g', 'C', 'h', 'a', 'i', 'n', ' ', 't', 'o', ' ', 'h', 'a', 'n', 'd', 'l', 'e', ' ', 'c', 'o', 'n', 'v', 'e', 'r', 's', 'a', 't', 'i', 'o', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'r', 'e', 'a', 's', 'o', 'n', 'i', 'n', 'g', '.', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# IMPORT NECESSARY MODULES\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# LOAD TEXT FROM FILE USING LANGCHAIN'S DOCUMENT LOADER\n",
    "loader = TextLoader(\"sample_text.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "document_text = documents[0].page_content  # EXTRACT TEXT CONTENT\n",
    "\n",
    "# FUNCTION TO SPLIT TEXT INTO SENTENCES\n",
    "def split_by_sentence(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\". \", chunk_size=1000)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# FUNCTION TO SPLIT TEXT INTO WORDS\n",
    "def split_by_word(text):\n",
    "    return text.split()  # SIMPLE WORD SPLIT USING SPACE\n",
    "\n",
    "# FUNCTION TO SPLIT TEXT INTO CHARACTERS\n",
    "def split_by_character(text):\n",
    "    return list(text)  # CONVERT STRING TO LIST OF CHARACTERS\n",
    "\n",
    "# DEMONSTRATING THE SPLITS\n",
    "print(\"\\n--- SPLIT BY PERIOD (SENTENCES) ---\")\n",
    "print(split_by_sentence(document_text))\n",
    "\n",
    "print(\"\\n--- SPLIT BY TOKEN (WORDS) ---\")\n",
    "print(split_by_word(document_text))\n",
    "\n",
    "print(\"\\n--- SPLIT BY CHARACTER ---\")\n",
    "print(split_by_character(document_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
