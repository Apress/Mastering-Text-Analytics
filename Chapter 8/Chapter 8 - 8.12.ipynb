{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f479428-4564-4dcf-bc93-6a31267b4f99",
   "metadata": {},
   "source": [
    "### Input and Output with Serialization in LangChain and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e462f-a96b-4cb7-90fa-dcdf83973a06",
   "metadata": {},
   "source": [
    "This program shows how to save and reload a setup for a language model (an AI that understands and generates text). It uses a tool called LangChain and OpenAI's API to:\n",
    "\n",
    "1. Create a task where the AI translates English text into French.  \n",
    "2. Save the setup (like a recipe) into a file so it can be reused later.  \n",
    "3. Load the saved setup back from the file.  \n",
    "4. Test the loaded setup by asking the AI to translate a sentence.  \n",
    "\n",
    "It's like writing down a recipe, storing it, and then using it again later to cook the same dish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fd3844-a2e9-4868-a8bb-813685aa1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the open ai API key from your text file\n",
    "f = open('C:\\\\Users\\\\Shailendra Kadre\\\\Desktop\\\\OPEN_AI_KEY.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f171f13-6d1a-406d-a7b4-9e1b450507c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized RunnableSequence saved to llm_chain.json.\n",
      "Loaded RunnableSequence successfully!\n",
      "Output: Bonjour, comment vas-tu ?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "\n",
    "# Step 1: Provide your OpenAI API key\n",
    "#api_key = \"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Step 2: Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "\n",
    "# Step 3: Create a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Translate this to French: {text}\"\n",
    ")\n",
    "\n",
    "# Step 4: Create a RunnableSequence (replaces LLMChain)\n",
    "chain = prompt | llm\n",
    "\n",
    "# Step 5: Serialize the RunnableSequence manually\n",
    "serialization_path = \"llm_chain.json\"\n",
    "# Save the necessary configuration parameters for reconstruction\n",
    "chain_dict = {\n",
    "    \"llm\": {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"temperature\": 0,\n",
    "        \"openai_api_key\": api_key\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"template\": prompt.template,\n",
    "        \"input_variables\": prompt.input_variables\n",
    "    }\n",
    "}\n",
    "with open(serialization_path, \"w\") as f:\n",
    "    json.dump(chain_dict, f)\n",
    "print(\"Serialized RunnableSequence saved to llm_chain.json.\")\n",
    "\n",
    "# Step 6: Load the serialized data\n",
    "with open(serialization_path, \"r\") as f:\n",
    "    chain_data = json.load(f)\n",
    "\n",
    "# Step 7: Reconstruct the RunnableSequence manually\n",
    "# Recreate the ChatOpenAI instance\n",
    "loaded_llm = ChatOpenAI(\n",
    "    model=chain_data[\"llm\"][\"model\"],\n",
    "    temperature=chain_data[\"llm\"][\"temperature\"],\n",
    "    openai_api_key=chain_data[\"llm\"][\"openai_api_key\"]\n",
    ")\n",
    "\n",
    "# Recreate the PromptTemplate instance\n",
    "loaded_prompt = PromptTemplate(\n",
    "    input_variables=chain_data[\"prompt\"][\"input_variables\"],\n",
    "    template=chain_data[\"prompt\"][\"template\"]\n",
    ")\n",
    "\n",
    "# Recreate the RunnableSequence\n",
    "loaded_chain = loaded_prompt | loaded_llm\n",
    "print(\"Loaded RunnableSequence successfully!\")\n",
    "\n",
    "# Step 8: Use the loaded chain to process input\n",
    "input_text = {\"text\": \"Hello, how are you?\"}\n",
    "output = loaded_chain.invoke(input_text)\n",
    "\n",
    "# Extract only the main content from the output\n",
    "if isinstance(output, dict) and \"content\" in output:\n",
    "    output_text = output[\"content\"]\n",
    "else:\n",
    "    output_text = output.content if hasattr(output, \"content\") else str(output)\n",
    "\n",
    "# Step 9: Print concise output\n",
    "print(f\"Output: {output_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcbed5-03b8-46b1-8ede-7992aaab8538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06bce1-66db-4ed8-9388-eaf0337e658f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355756d3-3678-4981-a9d4-147046ead808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86481b24-d22b-490e-a53b-d0b0e31cfa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
